_cfg_dict:
    value:
        auto_resume: false
        auto_scale_lr:
            base_batch_size: 16
            enable: false
        checkpoint_config:
            interval: 1
        custom_hooks:
            - type: NumClassCheckHook
        data:
            samples_per_gpu: 2
            test:
                ann_file: data/coco/annotations/instances_val2017.json
                img_prefix: data/coco/val2017/
                pipeline:
                    - type: LoadImageFromFile
                    - flip: false
                      img_scale:
                        - 1333
                        - 800
                      transforms:
                        - keep_ratio: true
                          type: Resize
                        - type: RandomFlip
                        - mean:
                            - 123.675
                            - 116.28
                            - 103.53
                          std:
                            - 58.395
                            - 57.12
                            - 57.375
                          to_rgb: true
                          type: Normalize
                        - size_divisor: 1
                          type: Pad
                        - keys:
                            - img
                          type: ImageToTensor
                        - keys:
                            - img
                          type: Collect
                      type: MultiScaleFlipAug
                type: CocoDataset
            train:
                ann_file: data/coco/annotations/instances_train2017.json
                filter_empty_gt: false
                img_prefix: data/coco/train2017/
                pipeline:
                    - type: LoadImageFromFile
                    - type: LoadAnnotations
                      with_bbox: true
                    - flip_ratio: 0.5
                      type: RandomFlip
                    - policies:
                        - - img_scale:
                                - - 480
                                  - 1333
                                - - 512
                                  - 1333
                                - - 544
                                  - 1333
                                - - 576
                                  - 1333
                                - - 608
                                  - 1333
                                - - 640
                                  - 1333
                                - - 672
                                  - 1333
                                - - 704
                                  - 1333
                                - - 736
                                  - 1333
                                - - 768
                                  - 1333
                                - - 800
                                  - 1333
                            keep_ratio: true
                            multiscale_mode: value
                            type: Resize
                        - - img_scale:
                                - - 400
                                  - 4200
                                - - 500
                                  - 4200
                                - - 600
                                  - 4200
                            keep_ratio: true
                            multiscale_mode: value
                            type: Resize
                          - allow_negative_crop: true
                            crop_size:
                                - 384
                                - 600
                            crop_type: absolute_range
                            type: RandomCrop
                          - img_scale:
                                - - 480
                                  - 1333
                                - - 512
                                  - 1333
                                - - 544
                                  - 1333
                                - - 576
                                  - 1333
                                - - 608
                                  - 1333
                                - - 640
                                  - 1333
                                - - 672
                                  - 1333
                                - - 704
                                  - 1333
                                - - 736
                                  - 1333
                                - - 768
                                  - 1333
                                - - 800
                                  - 1333
                            keep_ratio: true
                            multiscale_mode: value
                            override: true
                            type: Resize
                      type: AutoAugment
                    - mean:
                        - 123.675
                        - 116.28
                        - 103.53
                      std:
                        - 58.395
                        - 57.12
                        - 57.375
                      to_rgb: true
                      type: Normalize
                    - size_divisor: 1
                      type: Pad
                    - type: DefaultFormatBundle
                    - keys:
                        - img
                        - gt_bboxes
                        - gt_labels
                      type: Collect
                type: CocoDataset
            val:
                ann_file: data/coco/annotations/instances_val2017.json
                img_prefix: data/coco/val2017/
                pipeline:
                    - type: LoadImageFromFile
                    - flip: false
                      img_scale:
                        - 1333
                        - 800
                      transforms:
                        - keep_ratio: true
                          type: Resize
                        - type: RandomFlip
                        - mean:
                            - 123.675
                            - 116.28
                            - 103.53
                          std:
                            - 58.395
                            - 57.12
                            - 57.375
                          to_rgb: true
                          type: Normalize
                        - size_divisor: 1
                          type: Pad
                        - keys:
                            - img
                          type: ImageToTensor
                        - keys:
                            - img
                          type: Collect
                      type: MultiScaleFlipAug
                type: CocoDataset
            workers_per_gpu: 2
        data_root: data/coco/
        dataset_type: CocoDataset
        device: cuda
        dist_params:
            backend: nccl
        evaluation:
            interval: 1
            metric: bbox
        gpu_ids:
            - 0
        img_norm_cfg:
            mean:
                - 123.675
                - 116.28
                - 103.53
            std:
                - 58.395
                - 57.12
                - 57.375
            to_rgb: true
        lambda_2: 2
        load_from: null
        log_config:
            hooks:
                - type: TextLoggerHook
            interval: 50
        log_level: INFO
        lr_config:
            policy: step
            step:
                - 8
                - 11
        model:
            backbone:
                depth: 50
                frozen_stages: 1
                init_cfg:
                    checkpoint: torchvision://resnet50
                    type: Pretrained
                norm_cfg:
                    requires_grad: false
                    type: BN
                norm_eval: true
                num_stages: 4
                out_indices:
                    - 1
                    - 2
                    - 3
                style: pytorch
                type: ResNet
            bbox_head:
                - anchor_generator:
                    octave_base_scale: 8
                    ratios:
                        - 1
                    scales_per_octave: 1
                    strides:
                        - 8
                        - 16
                        - 32
                        - 64
                        - 128
                    type: AnchorGenerator
                  bbox_coder:
                    target_means:
                        - 0
                        - 0
                        - 0
                        - 0
                    target_stds:
                        - 0.1
                        - 0.1
                        - 0.2
                        - 0.2
                    type: DeltaXYWHBBoxCoder
                  feat_channels: 256
                  in_channels: 256
                  loss_bbox:
                    loss_weight: 24
                    type: GIoULoss
                  loss_centerness:
                    loss_weight: 12
                    type: CrossEntropyLoss
                    use_sigmoid: true
                  loss_cls:
                    alpha: 0.25
                    gamma: 2
                    loss_weight: 12
                    type: FocalLoss
                    use_sigmoid: true
                  num_classes: 9
                  stacked_convs: 1
                  type: CoATSSHead
            neck:
                act_cfg: null
                in_channels:
                    - 512
                    - 1024
                    - 2048
                kernel_size: 1
                norm_cfg:
                    num_groups: 32
                    type: GN
                num_outs: 4
                out_channels: 256
                type: ChannelMapper
            query_head:
                as_two_stage: true
                in_channels: 2048
                loss_bbox:
                    loss_weight: 5
                    type: L1Loss
                loss_cls:
                    alpha: 0.25
                    gamma: 2
                    loss_weight: 2
                    type: FocalLoss
                    use_sigmoid: true
                loss_iou:
                    loss_weight: 2
                    type: GIoULoss
                mixed_selection: true
                num_classes: 9
                num_query: 300
                positional_encoding:
                    normalize: true
                    num_feats: 128
                    offset: -0.5
                    type: SinePositionalEncoding
                sync_cls_avg_factor: true
                transformer:
                    decoder:
                        look_forward_twice: true
                        num_layers: 6
                        return_intermediate: true
                        transformerlayers:
                            attn_cfgs:
                                - dropout: 0
                                  embed_dims: 256
                                  num_heads: 8
                                  type: MultiheadAttention
                                - dropout: 0
                                  embed_dims: 256
                                  type: MultiScaleDeformableAttention
                            feedforward_channels: 2048
                            ffn_dropout: 0
                            operation_order:
                                - self_attn
                                - norm
                                - cross_attn
                                - norm
                                - ffn
                                - norm
                            type: DetrTransformerDecoderLayer
                        type: CoDeformableDetrTransformerDecoder
                    encoder:
                        num_layers: 6
                        transformerlayers:
                            attn_cfgs:
                                dropout: 0
                                embed_dims: 256
                                type: MultiScaleDeformableAttention
                            feedforward_channels: 2048
                            ffn_dropout: 0
                            operation_order:
                                - self_attn
                                - norm
                                - ffn
                                - norm
                            type: BaseTransformerLayer
                        type: DetrTransformerEncoder
                    num_co_heads: 2
                    type: CoDeformableDetrTransformer
                type: CoDeformDETRHead
                with_box_refine: true
            roi_head:
                - bbox_head:
                    bbox_coder:
                        target_means:
                            - 0
                            - 0
                            - 0
                            - 0
                        target_stds:
                            - 0.1
                            - 0.1
                            - 0.2
                            - 0.2
                        type: DeltaXYWHBBoxCoder
                    fc_out_channels: 1024
                    in_channels: 256
                    loss_bbox:
                        loss_weight: 120
                        type: GIoULoss
                    loss_cls:
                        loss_weight: 12
                        type: CrossEntropyLoss
                        use_sigmoid: false
                    num_classes: 9
                    reg_class_agnostic: false
                    reg_decoded_bbox: true
                    roi_feat_size: 7
                    type: Shared2FCBBoxHead
                  bbox_roi_extractor:
                    featmap_strides:
                        - 8
                        - 16
                        - 32
                        - 64
                    finest_scale: 112
                    out_channels: 256
                    roi_layer:
                        output_size: 7
                        sampling_ratio: 0
                        type: RoIAlign
                    type: SingleRoIExtractor
                  type: CoStandardRoIHead
            rpn_head:
                anchor_generator:
                    octave_base_scale: 4
                    ratios:
                        - 0.5
                        - 1
                        - 2
                    scales_per_octave: 3
                    strides:
                        - 8
                        - 16
                        - 32
                        - 64
                        - 128
                    type: AnchorGenerator
                bbox_coder:
                    target_means:
                        - 0
                        - 0
                        - 0
                        - 0
                    target_stds:
                        - 1
                        - 1
                        - 1
                        - 1
                    type: DeltaXYWHBBoxCoder
                feat_channels: 256
                in_channels: 256
                loss_bbox:
                    loss_weight: 12
                    type: L1Loss
                loss_cls:
                    loss_weight: 12
                    type: CrossEntropyLoss
                    use_sigmoid: true
                type: RPNHead
            test_cfg:
                - max_per_img: 100
                - rcnn:
                    max_per_img: 100
                    nms:
                        iou_threshold: 0.5
                        type: nms
                    score_thr: 0
                  rpn:
                    max_per_img: 1000
                    min_bbox_size: 0
                    nms:
                        iou_threshold: 0.7
                        type: nms
                    nms_pre: 1000
                - max_per_img: 100
                  min_bbox_size: 0
                  nms:
                    iou_threshold: 0.6
                    type: nms
                  nms_pre: 1000
                  score_thr: 0
            train_cfg:
                - assigner:
                    cls_cost:
                        type: FocalLossCost
                        weight: 2
                    iou_cost:
                        iou_mode: giou
                        type: IoUCost
                        weight: 2
                    reg_cost:
                        box_format: xywh
                        type: BBoxL1Cost
                        weight: 5
                    type: HungarianAssigner
                - rcnn:
                    assigner:
                        ignore_iof_thr: -1
                        match_low_quality: false
                        min_pos_iou: 0.5
                        neg_iou_thr: 0.5
                        pos_iou_thr: 0.5
                        type: MaxIoUAssigner
                    debug: false
                    pos_weight: -1
                    sampler:
                        add_gt_as_proposals: true
                        neg_pos_ub: -1
                        num: 512
                        pos_fraction: 0.25
                        type: RandomSampler
                  rpn:
                    allowed_border: -1
                    assigner:
                        ignore_iof_thr: -1
                        match_low_quality: true
                        min_pos_iou: 0.3
                        neg_iou_thr: 0.3
                        pos_iou_thr: 0.7
                        type: MaxIoUAssigner
                    debug: false
                    pos_weight: -1
                    sampler:
                        add_gt_as_proposals: false
                        neg_pos_ub: -1
                        num: 256
                        pos_fraction: 0.5
                        type: RandomSampler
                  rpn_proposal:
                    max_per_img: 1000
                    min_bbox_size: 0
                    nms:
                        iou_threshold: 0.7
                        type: nms
                    nms_pre: 4000
                - allowed_border: -1
                  assigner:
                    topk: 9
                    type: ATSSAssigner
                  debug: false
                  pos_weight: -1
            type: CoDETR
        mp_start_method: fork
        num_dec_layer: 6
        opencv_num_threads: 0
        optimizer:
            lr: 0.0002
            paramwise_cfg:
                custom_keys:
                    backbone:
                        lr_mult: 0.1
                    reference_points:
                        lr_mult: 0.1
                    sampling_offsets:
                        lr_mult: 0.1
            type: AdamW
            weight_decay: 0.0001
        optimizer_config:
            grad_clip:
                max_norm: 0.1
                norm_type: 2
        resume_from: null
        runner:
            max_epochs: 12
            type: EpochBasedRunner
        seed: 227665853
        test_pipeline:
            - type: LoadImageFromFile
            - flip: false
              img_scale:
                - 1333
                - 800
              transforms:
                - keep_ratio: true
                  type: Resize
                - type: RandomFlip
                - mean:
                    - 123.675
                    - 116.28
                    - 103.53
                  std:
                    - 58.395
                    - 57.12
                    - 57.375
                  to_rgb: true
                  type: Normalize
                - size_divisor: 1
                  type: Pad
                - keys:
                    - img
                  type: ImageToTensor
                - keys:
                    - img
                  type: Collect
              type: MultiScaleFlipAug
        train_pipeline:
            - type: LoadImageFromFile
            - type: LoadAnnotations
              with_bbox: true
            - flip_ratio: 0.5
              type: RandomFlip
            - policies:
                - - img_scale:
                        - - 480
                          - 1333
                        - - 512
                          - 1333
                        - - 544
                          - 1333
                        - - 576
                          - 1333
                        - - 608
                          - 1333
                        - - 640
                          - 1333
                        - - 672
                          - 1333
                        - - 704
                          - 1333
                        - - 736
                          - 1333
                        - - 768
                          - 1333
                        - - 800
                          - 1333
                    keep_ratio: true
                    multiscale_mode: value
                    type: Resize
                - - img_scale:
                        - - 400
                          - 4200
                        - - 500
                          - 4200
                        - - 600
                          - 4200
                    keep_ratio: true
                    multiscale_mode: value
                    type: Resize
                  - allow_negative_crop: true
                    crop_size:
                        - 384
                        - 600
                    crop_type: absolute_range
                    type: RandomCrop
                  - img_scale:
                        - - 480
                          - 1333
                        - - 512
                          - 1333
                        - - 544
                          - 1333
                        - - 576
                          - 1333
                        - - 608
                          - 1333
                        - - 640
                          - 1333
                        - - 672
                          - 1333
                        - - 704
                          - 1333
                        - - 736
                          - 1333
                        - - 768
                          - 1333
                        - - 800
                          - 1333
                    keep_ratio: true
                    multiscale_mode: value
                    override: true
                    type: Resize
              type: AutoAugment
            - mean:
                - 123.675
                - 116.28
                - 103.53
              std:
                - 58.395
                - 57.12
                - 57.375
              to_rgb: true
              type: Normalize
            - size_divisor: 1
              type: Pad
            - type: DefaultFormatBundle
            - keys:
                - img
                - gt_bboxes
                - gt_labels
              type: Collect
        work_dir: path_to_exp
        workflow:
            - - train
              - 1
_filename:
    value: projects\configs\co_deformable_detr\co_deformable_detr_r50_1x_coco.py
_text:
    value: |
        _base_ = [
            '../_base_/datasets/coco_detection.py',
            '../_base_/default_runtime.py'
        ]
        # model settings
        num_dec_layer = 6
        lambda_2 = 2.0

        model = dict(
            type='CoDETR',
            backbone=dict(
                type='ResNet',
                depth=50,
                num_stages=4,
                out_indices=(1, 2, 3),
                frozen_stages=1,
                norm_cfg=dict(type='BN', requires_grad=False),
                norm_eval=True,
                style='pytorch',
                init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),
            neck=dict(
                type='ChannelMapper',
                in_channels=[512, 1024, 2048],
                kernel_size=1,
                out_channels=256,
                act_cfg=None,
                norm_cfg=dict(type='GN', num_groups=32),
                num_outs=4),
            rpn_head=dict(
                type='RPNHead',
                in_channels=256,
                feat_channels=256,
                anchor_generator=dict(
                    type='AnchorGenerator',
                    octave_base_scale=4,
                    scales_per_octave=3,
                    ratios=[0.5, 1.0, 2.0],
                    strides=[8, 16, 32, 64, 128]),
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[.0, .0, .0, .0],
                    target_stds=[1.0, 1.0, 1.0, 1.0]),
                loss_cls=dict(
                    type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0*num_dec_layer*lambda_2),
                loss_bbox=dict(type='L1Loss', loss_weight=1.0*num_dec_layer*lambda_2)),
            query_head=dict(
                type='CoDeformDETRHead',
                num_query=300,
                num_classes=9,
                in_channels=2048,
                sync_cls_avg_factor=True,
                with_box_refine=True,
                as_two_stage=True,
                mixed_selection=True,
                transformer=dict(
                    type='CoDeformableDetrTransformer',
                    num_co_heads=2,
                    encoder=dict(
                        type='DetrTransformerEncoder',
                        num_layers=6,
                        transformerlayers=dict(
                            type='BaseTransformerLayer',
                            attn_cfgs=dict(
                                type='MultiScaleDeformableAttention', embed_dims=256, dropout=0.0),
                            feedforward_channels=2048,
                            ffn_dropout=0.0,
                            operation_order=('self_attn', 'norm', 'ffn', 'norm'))),
                    decoder=dict(
                        type='CoDeformableDetrTransformerDecoder',
                        num_layers=num_dec_layer,
                        return_intermediate=True,
                        look_forward_twice=True,
                        transformerlayers=dict(
                            type='DetrTransformerDecoderLayer',
                            attn_cfgs=[
                                dict(
                                    type='MultiheadAttention',
                                    embed_dims=256,
                                    num_heads=8,
                                    dropout=0.0),
                                dict(
                                    type='MultiScaleDeformableAttention',
                                    embed_dims=256,
                                    dropout=0.0)
                            ],
                            feedforward_channels=2048,
                            ffn_dropout=0.0,
                            operation_order=('self_attn', 'norm', 'cross_attn', 'norm',
                                             'ffn', 'norm')))),
                positional_encoding=dict(
                    type='SinePositionalEncoding',
                    num_feats=128,
                    normalize=True,
                    offset=-0.5),
                loss_cls=dict(
                    type='FocalLoss',
                    use_sigmoid=True,
                    gamma=2.0,
                    alpha=0.25,
                    loss_weight=2.0),
                loss_bbox=dict(type='L1Loss', loss_weight=5.0),
                loss_iou=dict(type='GIoULoss', loss_weight=2.0)),
            roi_head=[dict(
                type='CoStandardRoIHead',
                bbox_roi_extractor=dict(
                    type='SingleRoIExtractor',
                    roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
                    out_channels=256,
                    featmap_strides=[8, 16, 32, 64],
                    finest_scale=112),
                bbox_head=dict(
                    type='Shared2FCBBoxHead',
                    in_channels=256,
                    fc_out_channels=1024,
                    roi_feat_size=7,
                    num_classes=9,
                    bbox_coder=dict(
                        type='DeltaXYWHBBoxCoder',
                        target_means=[0., 0., 0., 0.],
                        target_stds=[0.1, 0.1, 0.2, 0.2]),
                    reg_class_agnostic=False,
                    reg_decoded_bbox=True,
                    loss_cls=dict(
                        type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0*num_dec_layer*lambda_2),
                    loss_bbox=dict(type='GIoULoss', loss_weight=10.0*num_dec_layer*lambda_2)))],
            bbox_head=[dict(
                type='CoATSSHead',
                num_classes=9,
                in_channels=256,
                stacked_convs=1,
                feat_channels=256,
                anchor_generator=dict(
                    type='AnchorGenerator',
                    ratios=[1.0],
                    octave_base_scale=8,
                    scales_per_octave=1,
                    strides=[8, 16, 32, 64, 128]),
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[.0, .0, .0, .0],
                    target_stds=[0.1, 0.1, 0.2, 0.2]),
                loss_cls=dict(
                    type='FocalLoss',
                    use_sigmoid=True,
                    gamma=2.0,
                    alpha=0.25,
                    loss_weight=1.0*num_dec_layer*lambda_2),
                loss_bbox=dict(type='GIoULoss', loss_weight=2.0*num_dec_layer*lambda_2),
                loss_centerness=dict(
                    type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0*num_dec_layer*lambda_2)),],
            # model training and testing settings
            train_cfg=[
                dict(
                    assigner=dict(
                        type='HungarianAssigner',
                        cls_cost=dict(type='FocalLossCost', weight=2.0),
                        reg_cost=dict(type='BBoxL1Cost', weight=5.0, box_format='xywh'),
                        iou_cost=dict(type='IoUCost', iou_mode='giou', weight=2.0))),
                dict(
                    rpn=dict(
                        assigner=dict(
                            type='MaxIoUAssigner',
                            pos_iou_thr=0.7,
                            neg_iou_thr=0.3,
                            min_pos_iou=0.3,
                            match_low_quality=True,
                            ignore_iof_thr=-1),
                        sampler=dict(
                            type='RandomSampler',
                            num=256,
                            pos_fraction=0.5,
                            neg_pos_ub=-1,
                            add_gt_as_proposals=False),
                        allowed_border=-1,
                        pos_weight=-1,
                        debug=False),
                    rpn_proposal=dict(
                        nms_pre=4000,
                        max_per_img=1000,
                        nms=dict(type='nms', iou_threshold=0.7),
                        min_bbox_size=0),
                    rcnn=dict(
                        assigner=dict(
                            type='MaxIoUAssigner',
                            pos_iou_thr=0.5,
                            neg_iou_thr=0.5,
                            min_pos_iou=0.5,
                            match_low_quality=False,
                            ignore_iof_thr=-1),
                        sampler=dict(
                            type='RandomSampler',
                            num=512,
                            pos_fraction=0.25,
                            neg_pos_ub=-1,
                            add_gt_as_proposals=True),
                        pos_weight=-1,
                        debug=False)),
                dict(
                    assigner=dict(type='ATSSAssigner', topk=9),
                    allowed_border=-1,
                    pos_weight=-1,
                    debug=False),],
            test_cfg=[
                dict(max_per_img=100),
                dict(
                    rpn=dict(
                        nms_pre=1000,
                        max_per_img=1000,
                        nms=dict(type='nms', iou_threshold=0.7),
                        min_bbox_size=0),
                    rcnn=dict(
                        score_thr=0.0,
                        nms=dict(type='nms', iou_threshold=0.5),
                        max_per_img=100)),
                dict(
                    nms_pre=1000,
                    min_bbox_size=0,
                    score_thr=0.0,
                    nms=dict(type='nms', iou_threshold=0.6),
                    max_per_img=100),
                # soft-nms is also supported for rcnn testing
                # e.g., nms=dict(type='soft_nms', iou_threshold=0.5, min_score=0.05)
            ])

        img_norm_cfg = dict(
            mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
        # train_pipeline, NOTE the img_scale and the Pad's size_divisor is different
        # from the default setting in mmdet.
        train_pipeline = [
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(
                type='AutoAugment',
                policies=[
                    [
                        dict(
                            type='Resize',
                            img_scale=[(480, 1333), (512, 1333), (544, 1333),
                                       (576, 1333), (608, 1333), (640, 1333),
                                       (672, 1333), (704, 1333), (736, 1333),
                                       (768, 1333), (800, 1333)],
                            multiscale_mode='value',
                            keep_ratio=True)
                    ],
                    [
                        dict(
                            type='Resize',
                            # The radio of all image in train dataset < 7
                            # follow the original impl
                            img_scale=[(400, 4200), (500, 4200), (600, 4200)],
                            multiscale_mode='value',
                            keep_ratio=True),
                        dict(
                            type='RandomCrop',
                            crop_type='absolute_range',
                            crop_size=(384, 600),
                            allow_negative_crop=True),
                        dict(
                            type='Resize',
                            img_scale=[(480, 1333), (512, 1333), (544, 1333),
                                       (576, 1333), (608, 1333), (640, 1333),
                                       (672, 1333), (704, 1333), (736, 1333),
                                       (768, 1333), (800, 1333)],
                            multiscale_mode='value',
                            override=True,
                            keep_ratio=True)
                    ]
                ]),
            dict(type='Normalize', **img_norm_cfg),
            dict(type='Pad', size_divisor=1),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
        ]
        # test_pipeline, NOTE the Pad's size_divisor is different from the default
        # setting (size_divisor=32). While there is little effect on the performance
        # whether we use the default setting or use size_divisor=1.
        test_pipeline = [
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(type='Normalize', **img_norm_cfg),
                    dict(type='Pad', size_divisor=1),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]

        data = dict(
            samples_per_gpu=2,
            workers_per_gpu=2,
            train=dict(filter_empty_gt=False, pipeline=train_pipeline),
            val=dict(pipeline=test_pipeline),
            test=dict(pipeline=test_pipeline))
        # optimizer
        optimizer = dict(
            type='AdamW',
            lr=2e-4,
            weight_decay=1e-4,
            paramwise_cfg=dict(
                custom_keys={
                    'backbone': dict(lr_mult=0.1),
                    'sampling_offsets': dict(lr_mult=0.1),
                    'reference_points': dict(lr_mult=0.1)
                }))
        optimizer_config = dict(grad_clip=dict(max_norm=0.1, norm_type=2))
        # learning policy
        lr_config = dict(policy='step', step=[11])
        runner = dict(type='EpochBasedRunner', max_epochs=12)
_wandb:
    value:
        cli_version: 0.18.7
        m: []
        python_version: 3.7.0
        t:
            "1":
                - 1
                - 5
                - 37
                - 38
                - 41
                - 49
                - 53
                - 55
                - 63
            "2":
                - 1
                - 5
                - 37
                - 38
                - 41
                - 49
                - 53
                - 55
                - 63
            "3":
                - 13
                - 16
                - 23
                - 55
            "4": 3.7.0
            "5": 0.18.7
            "8":
                - 3
                - 5
            "12": 0.18.7
            "13": windows-amd64
